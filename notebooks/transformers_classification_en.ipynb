{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-shot classification with transformer-based pre-trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains an example workflow how to work on custom containerized code that seamlessly interfaces with the Splunk Machine Learning Toolkit (MLTK) Container for TensorFlow. This script contains an example of how to conduct **End-to-End zero-shot classification task over English text (eg. dialogue transcript summaries)** using the transformers pipeline library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 0 - import libraries\n",
    "At stage 0 we define all imports necessary to run our subsequent code depending on various libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "name": "mltkc_import"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy path in runtime: /opt/conda/lib/python3.8/site-packages/numpy/__init__.py\n",
      "numpy version in runtime: 1.22.1\n"
     ]
    }
   ],
   "source": [
    "# this definition exposes all python module imports that should be available in all subsequent commands\n",
    "# import sys\n",
    "# sys.path.insert(1, '/opt/conda/lib/python3.8/site-packages')\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from transformers import pipeline\n",
    "\n",
    "import os\n",
    "path = os.path.abspath(np.__file__)\n",
    "print(\"numpy path in runtime: \" + path)\n",
    "print(\"numpy version in runtime: \" + np.__version__)\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"/opt/conda/lib/python3.8/site-packages/samsum_tok\", local_files_only=True)\n",
    "# summarizer = AutoModelForSeq2SeqLM.from_pretrained(\"/opt/conda/lib/python3.8/site-packages/samsum\", local_files_only=True)\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"philschmid/bart-large-cnn-samsum\")\n",
    "# # tokenizer.save_pretrained(\"/opt/conda/lib/python3.8/site-packages/samsum_tok\")\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(\"philschmid/bart-large-cnn-samsum\")\n",
    "# model.save_pretrained(\"/opt/conda/lib/python3.8/site-packages/samsum\")\n",
    "\n",
    "MODEL_DIRECTORY = \"/srv/app/model/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.22.1\n",
      "pandas version: 1.4.3\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing purposes\n",
    "print(\"numpy version: \" + np.__version__)\n",
    "print(\"pandas version: \" + pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "# summarizer = pipeline(\"summarization\", model=\"lidiya/bart-base-samsum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1 - get a data sample from Splunk\n",
    "In Splunk run a search to pipe a prepared dataset into this environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| makeresults\n",
    "| eval text = \"Client has a problem with the product he bought from the company this week. The size of the product in the picture is bigger than the size that is written in the description. Customer Service Representative will send him an accurate description of the method of use and he will follow up with one of the customer service representatives in the department of inquiries to clarify all the details.\"\n",
    "| fit MLTKContainer algo=transformers_classification_en mode=stage epochs=100 text into app:transformers_classification_model as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "name": "mltkc_stage"
   },
   "outputs": [],
   "source": [
    "# this cell is not executed from MLTK and should only be used for staging data into the notebook environment\n",
    "def stage(name):\n",
    "    with open(\"data/\"+name+\".csv\", 'r') as f:\n",
    "        df = pd.read_csv(f)\n",
    "    with open(\"data/\"+name+\".json\", 'r') as f:\n",
    "        param = json.load(f)\n",
    "    return df, param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text\n",
      "0  Customer Service Representative from the KDDI ...\n",
      "(1, 1)\n",
      "{'options': {'params': {'algo': 'transformers_classification_en2', 'mode': 'stage', 'epochs': '100'}, 'args': ['text'], 'feature_variables': ['text'], 'model_name': 'transformers_classification_model', 'output_name': 'text', 'algo_name': 'MLTKContainer', 'mlspl_limits': {'handle_new_cat': 'default', 'max_distinct_cat_values': '100', 'max_distinct_cat_values_for_classifiers': '100', 'max_distinct_cat_values_for_scoring': '100', 'max_fit_time': '600', 'max_inputs': '100000', 'max_memory_usage_mb': '4000', 'max_model_size_mb': '30', 'max_score_time': '600', 'use_sampling': 'true'}, 'kfold_cv': None}, 'feature_variables': ['text']}\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing purposes\n",
    "df, param = stage(\"transformers_classification_model\")\n",
    "print(df)\n",
    "print(df.shape)\n",
    "print(str(param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2 - create and initialize a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "name": "mltkc_init"
   },
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "# params: data and parameters\n",
    "# returns the model object which will be used as a reference to call fit, apply and summary subsequently\n",
    "def init(df,param):\n",
    "    \n",
    "    print(\"debug: start model initialization\")\n",
    "    classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "    model = classifier\n",
    "    print(\"debug: model initialized\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug: start model initialization\n",
      "debug: model initialized\n"
     ]
    }
   ],
   "source": [
    "model = init(df,param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3 - fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for this algorithm the model is pre-trained and therefore this stage is a placeholder only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "name": "mltkc_fit"
   },
   "outputs": [],
   "source": [
    "# returns a fit info json object\n",
    "def fit(model,df,param):\n",
    "    returns = {}\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4 - apply the model\n",
    "\n",
    "The variable **threshold** is used to adjust the posterior probability threshold for a tag to be returned when called. \n",
    "For example, threshold=0.1 returns the tags with scores higher than 0.1 from the pre-defined classes. The variable **ret_num** denotes the maximum returned tag number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "name": "mltkc_apply"
   },
   "outputs": [],
   "source": [
    "def apply(model,df,param):\n",
    "    threshold = 0.1\n",
    "    ret_num = 6\n",
    "    # define tags based on user-cases\n",
    "    classes = [\n",
    "        'technical support',\n",
    "        'telephone malfunction',\n",
    "        'television malfunction',\n",
    "        'wifi malfunction',\n",
    "        'line disturbance',\n",
    "        'payment issue',\n",
    "        'payment method',\n",
    "        'refund inquiry'\n",
    "        'product return',\n",
    "        'product exchange',\n",
    "        'purchase cancellation',\n",
    "        'product questions',\n",
    "        'user registration',\n",
    "        'password reset',\n",
    "        'user cancellation',\n",
    "        'user information change',\n",
    "        'follow up inquiries',\n",
    "        'other',\n",
    "        'spam'\n",
    "    ]\n",
    "    \n",
    "    X = df[param['feature_variables']].values.tolist()\n",
    "    temp_data=list()\n",
    "    \n",
    "    print(\"debug: read input\")\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        results = model(str(X[i]), classes)\n",
    "        vals = results[\"scores\"]\n",
    "        labels = results[\"labels\"]\n",
    "#         print(vals)\n",
    "        ret = \"\"\n",
    "        for i in range(ret_num):\n",
    "            if vals[i] > threshold:\n",
    "                ret += labels[i]\n",
    "                ret += \", \"\n",
    "        if ret == \"\":\n",
    "            ret += labels[0]\n",
    "        temp_data.append(ret)\n",
    "        \n",
    "    column_names=[\"tagging_result\"]\n",
    "    returns=pd.DataFrame(temp_data, columns=column_names)\n",
    "    print(\"debug: finished\")\n",
    "        \n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug: read input\n",
      "debug: finished\n",
      "                                 tagging_result\n",
      "0  wifi malfunction, technical support, other, \n"
     ]
    }
   ],
   "source": [
    "returns = apply(model,df,param)\n",
    "print(returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 5 - save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "name": "mltkc_save"
   },
   "outputs": [],
   "source": [
    "# save model to name in expected convention \"<algo_name>_<model_name>.h5\"\n",
    "def save(model,name):\n",
    "    # model will not be saved or reloaded as it is pre-built\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 6 - load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "name": "mltkc_load"
   },
   "outputs": [],
   "source": [
    "# load model from name in expected convention \"<algo_name>_<model_name>.h5\"\n",
    "def load(name):\n",
    "    # model will not be saved or reloaded as it is pre-built\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 7 - provide a summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "name": "mltkc_summary"
   },
   "outputs": [],
   "source": [
    "# return model summary\n",
    "def summary(model=None):\n",
    "    returns = {}\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Stages\n",
    "All subsequent cells are not tagged and can be used for further freeform code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
